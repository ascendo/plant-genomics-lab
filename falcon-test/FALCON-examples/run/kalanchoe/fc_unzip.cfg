[General]
job_type = SLURM
job_queue = cpu

[Unzip]
input_fofn= input.fofn
input_bam_fofn= input_bam.fofn

smrt_bin=/data/gpfs/home/dcurdie/scratch/falcon-2018.03.12-04.00-py2.7-ucs4/bin

sge_phasing= --ntasks 1 --nodes 1 --cpus-per-task 64 --mem 230g --time 3-11:20:00
sge_quiver= --ntasks 1 --nodes 1 --cpus-per-task 12 --mem 64g --time 10-11:20:00
sge_track_reads= --ntasks 1 --nodes 1 --cpus-per-task 12 --mem 128g --time 10-11:20:00
sge_blasr_aln= --ntasks 1 --nodes 1 --cpus-per-task 24 --mem 128g --time 10-11:20:00
sge_hasm=  --ntasks 1 --nodes 1 --cpus-per-task 48 --mem 128g --time 10-11:20:00
unzip_blasr_concurrent_jobs = 5000
unzip_phasing_concurrent_jobs = 5000
quiver_concurrent_jobs = 5000

##
# https://github.com/PacificBiosciences/FALCON-integrate/wiki/Configuring-Unzip

[job.defaults]
NPROC=16
njobs=5000
MB=85000

[job.step.unzip.quiver]
NPROC=48 # 48 processes per job
njobs=5000 # up to 30 concurrent jobs in queue
MB=125000

[job.step.unzip.hasm]
NPROC=24
njobs=5000
MB=81000

[job.step.unzip.track_reads]
NPROC=24
njobs=5000
MB=81000

